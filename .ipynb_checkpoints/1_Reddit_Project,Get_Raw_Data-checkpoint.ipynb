{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Reddit's API for Predicting WhichSubreddit?\n",
    "## Notebook 1:  Scraping Posts from Reddit's APIÂ¶"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2017-10-23T19:28:02.619411Z",
     "start_time": "2017-10-23T19:28:02.600856Z"
    }
   },
   "source": [
    "In this project, I will demionstrate two major skills. Collecting data via an API request and then building a binary predictor.\n",
    "\n",
    "There are two components to starting a data science problem: the problem statement, and acquiring the data.\n",
    "\n",
    "In this project, my problem statement will be: _Can I tell which Subreddit a particular post comes from based on a simple analysis of the text used by the author?_\n",
    "\n",
    "I will acquire my data by scraping the text and titles to posts from two distinctive subreddits from [Reddit homepage](https://www.reddit.com/), datascience and genetics. These posts will be uniquely identified by their id. If it becomes necessary to supplement my \"text only\" approach to determining Subreddit, I will also scrape the time posts were first made to reddit and the number of comments added to each post. Posts will be exported to my second notebook as a json file.\n",
    "\n",
    "Posts will be further processed in my second notebook and readied to be run through my models in the third notebook (see below)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {'User-agent': 'yukihadeishi .1'}\n",
    "res = requests.get('https://reddit.com/hot.json', headers=headers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "curr_json = res.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts = []\n",
    "def get_posts(sub = 'all', num_pages = 100):\n",
    "    counter = 0\n",
    "    after = None\n",
    "    while counter < num_pages:\n",
    "        if after == None:\n",
    "            params = {}\n",
    "        else:\n",
    "            params = {'after': after}\n",
    "        res = requests.get(f'https://reddit.com/r/{sub}/.json', params,\n",
    "                           headers=headers)\n",
    "        curr_json = res.json()\n",
    "        if(res.status_code!=200):\n",
    "            print('Try again')\n",
    "            return None\n",
    "        else:\n",
    "            page = curr_json['data'].get('children')\n",
    "        posts.extend(page)\n",
    "        after = curr_json['data']['after']\n",
    "        counter += 1\n",
    "        time.sleep(1)\n",
    "    return posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "datascience_posts = get_posts(sub='datascience', num_pages=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "genetics_posts = get_posts(sub='genetics', num_pages=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_posts = datascience_posts + genetics_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../data/test_dump3.json', 'w+') as f:\n",
    "    json.dump(reddit_posts, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reddit posts exported as json.dump for further processing."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
