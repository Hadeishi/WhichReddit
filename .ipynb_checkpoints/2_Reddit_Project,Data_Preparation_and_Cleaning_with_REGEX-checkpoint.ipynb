{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "focus": false,
    "id": "69b9a648-bcc7-490d-9f9b-ea244d156bd6",
    "nbpresent": {
     "id": "43123d5d-dbb6-42e8-ac2e-d067c29c7126"
    }
   },
   "source": [
    "# Using Reddit's API for Predicting WhichSubreddit?Â¶\n",
    "\n",
    "## Notebook 2:  Data Preparation and Cleaning with REGEX"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "6d3707e5-f320-4461-902b-d416bb5c2ec2"
    }
   },
   "source": [
    "#### Data imported as a json file and put in a dataframe. Duplicates will then be dropped and text from remaining posts processed (text and title combined, punctuation, numbers, and URL's removed, common words in English removed and text separated into individual words). Data saved and passed on to next notebook as a csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "nbpresent": {
     "id": "63036e7e-a78a-48f7-a308-3fa9d39f4ac1"
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import time\n",
    "import pandas as pd\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn import metrics\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "nbpresent": {
     "id": "0f03f8b1-55f5-4d12-93e7-9dc5c33c9c69"
    }
   },
   "outputs": [],
   "source": [
    "with open('../data/test_dump3.json', 'r') as f:\n",
    "    import_posts = json.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "dc90544a-750a-4a3e-b98c-04b1edfc79bb"
    }
   },
   "source": [
    "#### Divide data into target (\"which subreddit\") and dataframe of predictive features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "nbpresent": {
     "id": "e7b6adbb-3630-4342-8171-3e1667d750f0"
    }
   },
   "outputs": [],
   "source": [
    "def posts_as_DataFrame(posts, features = ['subreddit', 'author', 'id',\n",
    "                                          'title', 'selftext',\n",
    "                                          'created_utc', 'num_comments']):\n",
    "    feature_dict = [{feature : post['data'][feature] for feature in features}\n",
    "                 for post in posts]\n",
    "    return pd.DataFrame(feature_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "nbpresent": {
     "id": "8f67e766-69d5-4c0b-8947-2aee79993383"
    }
   },
   "outputs": [],
   "source": [
    "X_features_df = posts_as_DataFrame(import_posts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9988"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_features_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_df.drop_duplicates('id', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1870, 7)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features_df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "0e7caf4b-c9dd-4dc0-a163-490b379288de"
    }
   },
   "source": [
    "#### Prepare Text Data for analysis and join w/other features\n",
    "#### REGEX to remove URL's, whitespace, punctuation, convert to lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "nbpresent": {
     "id": "71b47228-dc03-4b04-90a3-fab74a5ef60d"
    }
   },
   "outputs": [],
   "source": [
    "# Combine title and body of post as X_text; drop body and title\n",
    "X_features_df['text'] = X_features_df['selftext'] + X_features_df['title']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_df.drop(columns = ['selftext', 'title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_text = []\n",
    "X_text = X_features_df['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "nbpresent": {
     "id": "4140d541-a7f9-43ef-b039-d7121c728ee3"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The Mod Team has decided that it would be nice to put together a list of recommended books, similar to [the podcast list] .\\n\\n**Please post any books that you have found particularly interesting or helpful for learning during your career.  Include the title with either an author or link.**\\n\\nSome restrictions:\\n\\n* Must be directly related to data science\\n* Non\\\\-fiction only\\n* Must be an actual **book**, not a blog post, scientific article, or website\\n* Nothing self\\\\-promotional\\n\\n ***** \\n\\nMy recommendations:\\n\\n* [Machine Learning: A Probabilistic Perspective] \\n* [Computer Age Statistical Inference] \\n* [Data Analysis Using Regression and Multilevel/Hierarchical Models] \\n* [Design and Analysis of Experiments] \\n* [Data Mining: Concepts and Techniques] \\n* [Active Learning] \\n* [All of Statistics: A Concise Course in Statistical Inference] DS Book Suggestions/Recommendations Megathread'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Clean URL's\n",
    "re.sub(\"(\\(http.*\\))\", ' ', X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "nbpresent": {
     "id": "ad5a7e8c-6cb9-4e6c-9f4d-4c8557a95cc3"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yukiharuhadeishi/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  from ipykernel import kernelapp as app\n"
     ]
    }
   ],
   "source": [
    "# Clean punctuation, newlines\n",
    "X_text[0] = re.sub(\"[^a-zA-Z]\", \" \", X_text[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['the', 'mod', 'team', 'has', 'decided']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert to all lowercase, split into individual words\n",
    "lowercase_X_test = X_text[0].lower()\n",
    "X_words = lowercase_X_test.split()\n",
    "X_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mod', 'team', 'decided', 'would', 'nice']"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#remove 'stopwords' (commonly occuring words in english language) from X_words\n",
    "X_words = [w for w in X_words if not w in stopwords.words(\"english\")]\n",
    "X_words[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data cleaning steps above into single function, to save time\n",
    "def post_to_words(X_text):\n",
    "    # Function to convert text from subreddit posts to a string of words\n",
    "    # The input is a single string (obtained in \"get raw data\" notebook), and \n",
    "    # the output is a single string (a preprocessed reddit post)\n",
    "    #\n",
    "    # Clean URL's\n",
    "    X_text = re.sub(\"(\\(http.*\\))\", ' ', X_text)\n",
    "    # Clean punctuation, newlines\n",
    "    X_text = re.sub(\"[^a-zA-Z]\", \" \", X_text)\n",
    "    #\n",
    "    # Convert to all lowercase, split into individual words\n",
    "    X_words = X_text.lower().split()\n",
    "    #\n",
    "    # In Python, searching a set is much faster than searching\n",
    "    #   a list, so convert the stop words to a set\n",
    "    stops = set(stopwords.words('english'))\n",
    "    # \n",
    "    # Remove stop words\n",
    "    meaningful_words = [w for w in X_words if not w in stops]\n",
    "    #\n",
    "    # Join the words back into one string separated by space, \n",
    "    # and return the result.\n",
    "    return(\" \".join(meaningful_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Apply function above to text of posts, stepping through each post, i."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1870"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the number of posts based on the dataframe column size\n",
    "num_posts = X_features_df.shape[0]\n",
    "\n",
    "# Initialize an empty list to hold the clean posts\n",
    "clean_X_text = []\n",
    "num_posts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_features_df.text = X_features_df.text.apply(post_to_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>created_utc</th>\n",
       "      <th>id</th>\n",
       "      <th>num_comments</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Omega037</td>\n",
       "      <td>1.526405e+09</td>\n",
       "      <td>8jneyb</td>\n",
       "      <td>42</td>\n",
       "      <td>datascience</td>\n",
       "      <td>mod team decided would nice put together list ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Omega037</td>\n",
       "      <td>1.527799e+09</td>\n",
       "      <td>8nlsqi</td>\n",
       "      <td>18</td>\n",
       "      <td>datascience</td>\n",
       "      <td>weekly entering amp transitioning thread quest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One_Last_Thyme</td>\n",
       "      <td>1.528047e+09</td>\n",
       "      <td>8oa4uy</td>\n",
       "      <td>6</td>\n",
       "      <td>datascience</td>\n",
       "      <td>hey guys looking input project working interns...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Hydralyze</td>\n",
       "      <td>1.528048e+09</td>\n",
       "      <td>8oa880</td>\n",
       "      <td>2</td>\n",
       "      <td>datascience</td>\n",
       "      <td>lots google sheets work others spreadsheet gen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FeelTheQuickening</td>\n",
       "      <td>1.528050e+09</td>\n",
       "      <td>8oaiac</td>\n",
       "      <td>2</td>\n",
       "      <td>datascience</td>\n",
       "      <td>hello industrial engineer experience dealing d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              author   created_utc      id  num_comments    subreddit  \\\n",
       "0           Omega037  1.526405e+09  8jneyb            42  datascience   \n",
       "1           Omega037  1.527799e+09  8nlsqi            18  datascience   \n",
       "2     One_Last_Thyme  1.528047e+09  8oa4uy             6  datascience   \n",
       "3          Hydralyze  1.528048e+09  8oa880             2  datascience   \n",
       "4  FeelTheQuickening  1.528050e+09  8oaiac             2  datascience   \n",
       "\n",
       "                                                text  \n",
       "0  mod team decided would nice put together list ...  \n",
       "1  weekly entering amp transitioning thread quest...  \n",
       "2  hey guys looking input project working interns...  \n",
       "3  lots google sheets work others spreadsheet gen...  \n",
       "4  hello industrial engineer experience dealing d...  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_features_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save X_features_df as a csv for use in the next notebook:  Vectorizing and Model Building!\n",
    "X_features_df.to_csv('../data/X_features_df3.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "e3246bf0-4d8e-486c-9d6c-ae6091c890fd"
    }
   },
   "source": [
    "Save X_features_df as a csv for use in the next notebook:  Vectorizing and Model Building!"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
